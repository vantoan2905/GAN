

# GAN Training for Image Generation

This repository implements a Generative Adversarial Network (GAN) for generating images. The GAN consists of two primary components:

- **Generator**: Takes a latent vector as input and generates synthetic images.
- **Discriminator**: Attempts to classify images as real (from the dataset) or fake (generated by the generator).

### Example:
- **Generator Output**: from ![alt text](sample_data/image/00001.jpg) to ![alt text](model/final_samples.png)

## Clone the Project

```bash
git clone https://github.com/vantoan2905/GAN_fake_image.git
```

Then navigate to the project folder:

```bash
cd GAN_fake_image
cd DCGAN
```
Or you can navigate to the `model` folder:

```bash
cd model
```

Then, open the file `./develop.ipynb` for a miniature version of the project.

## Requirements

### 1. Create a Virtual Environment

You can create the environment using conda. First, make sure you have conda or Miniconda installed after cloning the project.

```bash
conda create --name GAN_fake_image python=3.10
conda activate GAN_fake_image
```

### 2. Install Required Packages

After activating the environment, install the required dependencies:

```bash
pip install torch torchvision matplotlib pillow numpy
```


## Project Structure

The project consists of the following main files:

- **`generator.py`**: Contains the `Generator` and `Generator_256` classes for creating generator models for different image sizes.
- **`discriminator.py`**: Contains the `Discriminator` and `Discriminator_256` classes for creating discriminator models for different image sizes.
- **`customDataset.py`**: Custom dataset class for loading and transforming images.
- **`train.py`**: Main script for training the GAN model, which includes training routines, model saving/loading, and image generation.

## Training a GAN

### 1. Data Preparation

Before training the GAN, you need a directory containing the images you want the GAN to learn from. The script supports image sizes of 128px and 256px, as specified during training.

- Organize your images into a folder and provide the path to the folder when running the script.

### 2. Running the Training

You can run the training script by specifying the directory path containing your images and the desired mode (128 or 256 for image size). The script will train the model and save the generated images during training.

```bash
python train.py /path/to/your/images --latent_dim 100 --batch_size 16 --num_epochs 300 --channels 3 --mode 128
```

Or for 256px images:

```bash
python train.py /path/to/your/images --latent_dim 100 --batch_size 16 --num_epochs 300 --channels 3 --mode 256
```

### 3. Modes

There are two modes for image generation based on the size:

- **128px Mode**: For generating images of size 128x128px (`--mode 128`).
- **256px Mode**: For generating images of size 256x256px (`--mode 256`).

### 4. Output

During training, the script will output:

- **Generated Samples**: Images generated by the generator at regular intervals (every 10 epochs).
- **Model Checkpoints**: The trained generator will be saved to a file at the end of training.
  - **generator_final.pth**: The final generator model.
  - **generator_error_state.pth**: The state of the generator in case of interrupted training.

### 5. Image Generation After Training

You can use the trained generator model to generate new images after training:

```python
from train import load_generator, generate_images

# Load trained generator
generator = load_generator(latent_dim=100, path='generator_final.pth')

# Generate images
generate_images(generator, num_images=16, latent_dim=100, output_path='generated_images.png')
```

## Arguments

### Required Arguments:

- `path`: Path to the directory containing images for training.
- `mode`: Image size mode (`128` for 128px images, `256` for 256px images).

### Optional Arguments:

- `latent_dim`: Dimensionality of the latent vector (default: 100).
- `batch_size`: Batch size for training (default: 16).
- `num_epochs`: Number of epochs to train the GAN (default: 300).
- `channels`: Number of channels in the input images (default: 3, for RGB images).

## Notes

- **GPU Support**: The code supports GPU training if a CUDA-compatible device is available. If running on a CPU, the code will automatically fall back to CPU.
- **Image Format**: The script assumes input images are in a format supported by PIL (e.g., PNG, JPG).

## License

This code is released under the MIT License.
